# configs/inference.yaml

root_dir: "./inferences"
base_name: "runs"
seed: 42
use_gpu: True

inference:
  batch_size: 1
  num_workers: 8
  data_path: "data/processed/test/sample_images"
  checkpoint_path: "experiments/exp-01-testing-pipeline-2026-02-14/checkpoints"
  checkpoint_name: "best_val_loss.pth"
  tags: ["test", "inference", "pipeline"]

models:
  - name: "n2n-new"
    model_params: 
      in_channels: 1
      out_channels: 1
      depth: 4
      base_channels: 48
      activation: "leaky_relu"

